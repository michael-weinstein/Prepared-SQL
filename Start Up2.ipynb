{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#query building functions and objects\n",
    "class MapReduce(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = [str(datum) for datum in data]\n",
    "        self.generate()\n",
    "        \n",
    "    def generate(self):\n",
    "        self.hashTable = {}\n",
    "        for datum in self.data:\n",
    "            try:\n",
    "                self.hashTable[datum] += 1\n",
    "            except KeyError:\n",
    "                self.hashTable[datum] = 1\n",
    "        keyList = list(self.hashTable.keys())\n",
    "        keyList.sort()\n",
    "        self.map = keyList\n",
    "        self.reduced = []\n",
    "        for key in self.map:\n",
    "            self.reduced.append([key,self.hashTable[key]])\n",
    "        return True\n",
    "\n",
    "class RareCodingVariants(object):\n",
    "    \n",
    "    def __init__(self, table, suffix = \"_rare_coding\"):\n",
    "        self.inputTable = table\n",
    "        self.tablename = table + suffix\n",
    "        \n",
    "    def buildTables(self):\n",
    "        temptable = self.tablename + \"_temp\"\n",
    "        query = \"\"\n",
    "        query += \"CREATE TABLE \" + temptable + \" as SELECT * from \" + self.inputTable + \" where \\\n",
    "\\n(AfricanHapMapFreq < 1.0) and (AsianHapMapFreq < 1.0) and (EuropeanHapMapFreq < 1.0) and \\\n",
    "\\n(dbSNP_5_percent_in_all != 'TRUE') and (dbSNP_5_percent_in_any != 'TRUE') and \\\n",
    "\\n(F_rarest_allele < 0.01) and (MAFinESP < 0.01) and (functionGVS NOT IN \\\n",
    "\\n('intron' , 'synonymous', '5-prime-UTR', '3-prime-UTR', 'non-coding-exon', \\\n",
    "\\n'upstream-gene', 'downstream-gene', 'intergenic')) \\\n",
    "\\nGROUP by varMD5; \\\n",
    "\\nDELETE from \" + self.inputTable + \"VCF where instr(uniLocVCF, 'GL') != 0; \\\n",
    "\\nCREATE TABLE \" + self.tablename + \" as select * from \" + temptable + \" left join \" + self.inputTable + \"VCF on varMD5 = varMD5VCF; \\\n",
    "\\nDROP TABLE \" + temptable + \"; \\\n",
    "\\nALTER TABLE \" + self.tablename + \" ADD INDEX (varMD5), ADD INDEX (uniLoc), ADD INDEX (geneList);\"\n",
    "        return query\n",
    "    \n",
    "    def getVariants(self):\n",
    "        query = \"SELECT * FROM \" + self.tablename + \";\"\n",
    "        return query\n",
    "    \n",
    "    def countVariants(self, unique = False):\n",
    "        query = \"\"\n",
    "        if unique:\n",
    "            query += \"SELECT COUNT(distinct varMD5) \"\n",
    "        if not unique:\n",
    "            query += \"SELECT COUNT(*) \"\n",
    "        query += \"from \" + self.tablename + \";\"\n",
    "        return query\n",
    "\n",
    "    \n",
    "class KnownGenes(object):\n",
    "    \n",
    "    def __init__(self, table, knownGeneList, columnName = 'geneList'):\n",
    "        self.table = table\n",
    "        try:\n",
    "            assert hasattr(knownGeneList, '__iter__') and not type(knownGeneList) is str\n",
    "        except:\n",
    "            raise TypeError(\"List of known genes must be passed as a list or a tupple\")\n",
    "        self.knownGeneList = list(knownGeneList)\n",
    "        self.knownGeneList = [gene.strip() for gene in self.knownGeneList]\n",
    "        self.knownGeneList = [\"'\" + gene + \"',\" for gene in self.knownGeneList]\n",
    "        \n",
    "    def listFromFile(file):\n",
    "        if not hasattr(file, 'read'):\n",
    "            raise TypeError(\"Object passed must be a file\")\n",
    "        linecollector = []\n",
    "        line = file.readline()\n",
    "        while line:\n",
    "            if not line[0] == '#':\n",
    "                linecollector.append(line.strip())\n",
    "            line = file.readline()\n",
    "        return linecollector\n",
    "    \n",
    "    def hashedListFromFile(file):\n",
    "        if not hasattr(file, 'read'):\n",
    "            raise TypeError(\"Object passed must be a file\")\n",
    "        listcollector = {}\n",
    "        line = file.readline()\n",
    "        line = line.strip()\n",
    "        if line[0] != \"#\":\n",
    "            raise RuntimeError(\"First line must be a group name and start with a # symbol\")\n",
    "        while line:\n",
    "            if line[0] == \"#\":\n",
    "                currentlist = line.replace(\"#\",\"\")\n",
    "                currentlist = currentlist.replace(\"\\t\",\" \")\n",
    "                listcollector[currentlist] = []\n",
    "            else:\n",
    "                listcollector[currentlist].append(line.strip())\n",
    "            line = file.readline()\n",
    "            line = line.strip()\n",
    "        return listcollector\n",
    "       \n",
    "    def getVariants(self, columnName = \"geneList\"):\n",
    "        knownGeneString = \" \".join(self.knownGeneList)\n",
    "        knownGeneString = knownGeneString.strip()\n",
    "        knownGeneString = knownGeneString.strip(\",\")\n",
    "        query = \"\"\n",
    "        query += \"SELECT * FROM \" + self.table + \" where \" + columnName + \" in (\" + knownGeneString + \") ORDER by geneList;\"\n",
    "        return query\n",
    "    \n",
    "\n",
    "class Homozygous(object):\n",
    "    \n",
    "    def __init__(self, table, readCutoff = 0.1, suffix = \"_homozygosity\"):\n",
    "        self.inputTable = table\n",
    "        self.tablename = table + suffix\n",
    "        if readCutoff:\n",
    "            try:\n",
    "                readCutoff = float(readCutoff)\n",
    "            except TypeError:\n",
    "                raise TypeError(\"Read cutoff value must be a number.\")\n",
    "            if readCutoff >= 1.0:\n",
    "                readCutoff = readCutoff/100\n",
    "            try:\n",
    "                assert readCutoff <= 1.0\n",
    "            except:\n",
    "                raise ValueError(\"Percent for cutoff must be below 100\")\n",
    "            if readCutoff > 0.5:\n",
    "                readCutoff = 1.0 - readCutoff\n",
    "        self.readCutoff = readCutoff\n",
    "        \n",
    "    def buildTables(self):\n",
    "        query = \"\"\n",
    "        query += \"CREATE TABLE \" + self.tablename + \" as SELECT * from \" + self.inputTable + \" \\\n",
    "\\nWHERE sampleGenotype NOT IN ('S' , 'R', 'Y', 'M', 'K', 'W') \\\n",
    "\\nAND (INSTR(sampleGenotype, '/') = 0 OR substring_index(sampleGenotype, '/', 1) = substring_index(sampleGenotype, '/', -1))\"\n",
    "        if self.readCutoff:\n",
    "            query += \"\\nOR (Ref_read_percentVCF < \" + str(round(self.readCutoff, 4)) + \");\\n\"\n",
    "        else:\n",
    "            query += \";\\n\"\n",
    "        query += \"ALTER TABLE \" + self.tablename + \" ADD INDEX (varMD5), ADD INDEX (uniLoc), ADD INDEX (geneList);\"\n",
    "        return query\n",
    "   \n",
    "    def getVariants(self):\n",
    "        query = \"SELECT * FROM \" + self.tablename + \";\"\n",
    "        return query\n",
    "       \n",
    "    def countVariants(self, unique = False):\n",
    "        query = \"\"\n",
    "        if unique:\n",
    "            query += \"SELECT COUNT(distinct varMD5) \"\n",
    "        if not unique:\n",
    "            query += \"SELECT COUNT(*) \"\n",
    "        query += \"from \" + self.tablename + \";\"\n",
    "        \n",
    "        \n",
    "class CompoundHet(object):\n",
    "    \n",
    "    def __init__(self, table, suffix = \"_compound_het\"):\n",
    "        self.inputTable = table\n",
    "        self.tablename = table + suffix\n",
    "        \n",
    "    def buildTables(self):\n",
    "        hitcounts = self.inputTable + \"_hit_count\"\n",
    "        query = \"\"\n",
    "        query += \"CREATE TABLE \" + hitcounts + \" as \\\n",
    "\\nSELECT distict varMD5, uniLoc, geneList, count(*) hits \\\n",
    "\\nFROM \" + self.inputTable + \" group by geneList; \\\n",
    "\\nCREATE TABLE \" + self.tablename + \" as SELECT * from \" + self.inputTable + \" \\\n",
    "\\nWHERE geneList in (SELECT distinct geneList from \" + hitcounts + \" WHERE \\\n",
    "hits > 1) \\\n",
    "\\nORDER by geneList asc;\"\n",
    "        return query\n",
    "    \n",
    "    def getVariants(self):\n",
    "        query = \"SELECT * FROM \" + self.tablename + \";\"\n",
    "        return query\n",
    "        \n",
    "    def countVariants(self, unique = False):\n",
    "        query = \"\"\n",
    "        if unique:\n",
    "            query += \"SELECT COUNT(distinct varMD5) \"\n",
    "        if not unique:\n",
    "            query += \"SELECT COUNT(*) \"\n",
    "        query += \"from \" + self.tablename + \";\"\n",
    "        return query\n",
    "    \n",
    "    def countGenes(self):\n",
    "        query = \"\"\n",
    "        query += \"SELECT COUNT(distinct geneList)from \" + self.tablename + \";\"\n",
    "        return query\n",
    "    \n",
    "    \n",
    "class DeNovoChanges(object):\n",
    "    \n",
    "    def __init__(self, proband, parent1 = \"\", parent2 = \"\", group = \"\"):\n",
    "        if not (proband and parent1 and parent2) or not type(proband) is str:\n",
    "            try:\n",
    "                assert hasattr(proband, '__iter__') and len(proband) == 3\n",
    "                self.group = parent1\n",
    "                self.parent2 = proband[2]\n",
    "                self.parent1 = proband[1]\n",
    "                self.proband = proband[0]\n",
    "            except:\n",
    "                raise RuntimeError(\"Finding changed variants requires passing proband and original as either arguments or a tupple of two identifiers\")\n",
    "        else:\n",
    "            self.proband = proband\n",
    "            self.group = group\n",
    "            self.parent1 = parent1\n",
    "            self.parent2 = parent2            \n",
    "        \n",
    "    def buildTables(self):\n",
    "        query = \"\"        \n",
    "        query += \"DELETE FROM \" + self.proband + \"VCF where instr(uniLocVCF, 'GL') != 0;\\n\"\n",
    "        query += \"DELETE FROM \" + self.parent1 + \"VCF where instr(uniLocVCF, 'GL') != 0;\\n\"\n",
    "        \n",
    "        query += \"CREATE TABLE \" + self.proband + self.group + \"_genotemp1 as select uniLoc, varMD5, geneList, GenotypeVCF proband_geno, \\\n",
    "\\nfunctionGVS, functionDBSNP, aminoAcids, proteinPosition, distanceToSplice, polyPhen, granthamScore, scorePhastCons, scoreCADD, \\\n",
    "\\nF_rarest_allele, MAFinESP, FILTERVCF, \\\n",
    "\\nGenotype_QualityVCF, Variant_Confidence_Quality_by_DepthVCF, \\\n",
    "\\nDepth_CountedVCF depth_proband, Reference_readsVCF Ref_reads_proband, Alt_readsVCF Alt_read_proband, \\\n",
    "\\nRef_read_percentVCF Ref_read_pct_proband, A_readVCF A_read_proband, G_readVCF G_read_proband, \\\n",
    "\\nT_readVCF T_read_proband, C_readVCF C_read_proband, A_percentVCF A_percent_proband, G_percentVCF G_percent_proband, \\\n",
    "\\nT_percentVCF T_percent_proband, C_percentVCF C_percent_proband from \" + self.proband + self.group + \"; \\n\"  \n",
    "        query += \"ALTER TABLE \" + self.proband + self.group + \"_genotemp1 ADD INDEX (uniLoc), ADD INDEX (geneList), ADD INDEX(varMD5);\\n\"\n",
    "        query += \"CREATE TABLE \" + self.proband + self.group + \"_genotemp2 as select \" + self.proband + self.group + \"_genotemp1.*, \\\n",
    "\\n\" + self.parent1 + \"VCF.GenotypeVCF p1_geno, \" + self.parent1 + \"VCF.Depth_CountedVCF Depth_p1, \\\n",
    "\\n\" + self.parent1 + \"VCF.Reference_readsVCF Ref_read_p1, \" + self.parent1 + \"VCF.Alt_readsVCF Alt_read_p1, \\\n",
    "\\n\" + self.parent1 + \"VCF.Ref_read_percentVCF Ref_read_pct_p1, \" + self.parent1 + \"VCF.A_readVCF A_read_p1, \\\n",
    "\\n\" + self.parent1 + \"VCF.G_readVCF G_read_p1, \" + self.parent1 + \"VCF.T_readVCF T_read_p1, \" + self.parent1 + \"VCF.C_readVCF C_read_p1,\\\n",
    "\\n\" + self.parent1 + \"VCF.A_percentVCF A_percent_p1, \" + self.parent1 + \"VCF.G_percentVCF G_percent_p1, \" + self.parent1 + \"VCF.T_percentVCF T_percent_p1, \\\n",
    "\\n\" + self.parent1 + \"VCF.C_percentVCF C_percent_p1 from \" + self.proband + self.group + \"_genotemp1 left join \" + self.parent1 + \"VCF on \\\n",
    "\\n\" + self.proband + self.group + \"_genotemp1.varMD5 = \" + self.parent1 + \"VCF.varMD5VCF;\\n\"\n",
    "        query += \"DROP TABLE \" + self.proband + self.group + \"_genotemp1;\\n\"\n",
    "        query += \"ALTER TABLE \" + self.proband + group  + \"_genotemp2 ADD INDEX (uniLoc), ADD INDEX (geneList), ADD INDEX(varMD5);\\n\"\n",
    "        query += \"CREATE TABLE \" + self.proband + self.group + \"_genotypes as select \" + self.proband + self.group + \"_genotemp2.*, \\\n",
    "\\n\" + self.parent2 + \"VCF.GenotypeVCF p2_geno, \" + self.parent2 + \"VCF.Depth_CountedVCF Depth_p2, \\\n",
    "\\n\" + self.parent2 + \"VCF.Reference_readsVCF Ref_read_p2, \" + self.parent2 + \"VCF.Alt_readsVCF Alt_read_p2, \\\n",
    "\\n\" + self.parent2 + \"VCF.Ref_read_percentVCF Ref_read_pct_p2, \" + self.parent2 + \"VCF.A_readVCF A_read_p2, \\\n",
    "\\n\" + self.parent2 + \"VCF.G_readVCF G_read_p2, \" + self.parent2 + \"VCF.T_readVCF T_read_p2, \" + self.parent2 + \"VCF.C_readVCF C_read_p2,\\\n",
    "\\n\" + self.parent2 + \"VCF.A_percentVCF A_percent_p2, \" + self.parent2 + \"VCF.G_percentVCF G_percent_p2, \" + self.parent2 + \"VCF.T_percentVCF T_percent_p2, \\\n",
    "\\n\" + self.parent2 + \"VCF.C_percentVCF C_percent_p2 from \" + self.proband + self.group + \"_genotemp2 left join \" + self.parent2 + \"VCF on \\\n",
    "\\n\" + self.proband + self.group + \"_genotemp2.varMD5 = \" + self.parent2 + \"VCF.varMD5VCF;\\n\"\n",
    "        query += \"DROP TABLE \" + self.proband + self.group + \"_genotemp2;\\n\"\n",
    "        query += \"ALTER TABLE \" + self.proband + group  + \"_genotypes ADD INDEX (uniLoc), ADD INDEX (geneList), ADD INDEX(varMD5);\\n\"\n",
    "        self.genotable = self.proband + self.group + \"_genotypes\"\n",
    "        return query\n",
    "    \n",
    "    def getVariants(self, stringent = False):\n",
    "        query = \"\"\n",
    "        query += \"SELECT * FROM \" + self.proband + self.group + \"_genotypes WHERE \\\n",
    "\\n(substring_index(proband_geno, '/', 1) != substring_index(proband_geno, '/', -1)) and \\\n",
    "\\n((substring_index(proband_geno, '/', 1) != '0' and substring_index(proband_geno, '/', 1) not in \\\n",
    "\\n (substring_index(mom_geno, '/', 1), substring_index(mom_geno, '/', -1), \\\n",
    "\\n  substring_index(dad_geno, '/', 1), substring_index(dad_geno, '/', -1))) \\\n",
    "\\nor \\\n",
    "\\n(substring_index(proband_geno, '/', -1) != '0' and substring_index(proband_geno, '/', -1) not in \\\n",
    "\\n (substring_index(mom_geno, '/', 1), substring_index(mom_geno, '/', -1), \\\n",
    "\\n  substring_index(dad_geno, '/', 1), substring_index(dad_geno, '/', -1)) \\\n",
    "\\n))\"\n",
    "        if not stringent:\n",
    "            query += \";\\n\"\n",
    "        if stringent:\n",
    "            query += \"\\nand proband_geno != './.' and p1_geno != './.' and p2_geno != './.';\\n\"\n",
    "        return query   \n",
    "    \n",
    "    def countVariants(self, stringent = False, unique = False):\n",
    "        query = \"\"\n",
    "        if unique:\n",
    "            query += \"SELECT COUNT(distinct varMD5) FROM \"\n",
    "        if not unique:\n",
    "            query += \"SELECT COUNT(*) FROM \"\n",
    "        query += self.proband + self.group + \"_genotypes WHERE \\\n",
    "\\n(substring_index(proband_geno, '/', 1) != substring_index(proband_geno, '/', -1)) and \\\n",
    "\\n((substring_index(proband_geno, '/', 1) != '0' and substring_index(proband_geno, '/', 1) not in \\\n",
    "\\n (substring_index(mom_geno, '/', 1), substring_index(mom_geno, '/', -1), \\\n",
    "\\n  substring_index(dad_geno, '/', 1), substring_index(dad_geno, '/', -1))) \\\n",
    "\\nor \\\n",
    "\\n(substring_index(proband_geno, '/', -1) != '0' and substring_index(proband_geno, '/', -1) not in \\\n",
    "\\n (substring_index(mom_geno, '/', 1), substring_index(mom_geno, '/', -1), \\\n",
    "\\n  substring_index(dad_geno, '/', 1), substring_index(dad_geno, '/', -1)) \\\n",
    "\\n))\"\n",
    "        if not stringent:\n",
    "            query += \";\\n\"\n",
    "        if stringent:\n",
    "            query += \"\\nand proband_geno != './.' and p1_geno != './.' and p2_geno != './.';\\n\"\n",
    "        return query \n",
    "    \n",
    "    \n",
    "class SomaticChanges(object):\n",
    "    \n",
    "    def __init__(self, proband, parent1 = \"\", group = \"\"):\n",
    "        if not (proband and parent1) or not type(proband) is str:\n",
    "            try:\n",
    "                assert hasattr(proband, '__iter__') and len(proband) == 2\n",
    "                self.group = parent1\n",
    "                self.parent1 = proband[1]\n",
    "                self.proband = proband[0]\n",
    "            except:\n",
    "                raise RuntimeError(\"Finding changed variants requires passing proband and original as either arguments or a tupple of two identifiers\")\n",
    "        else:\n",
    "            self.proband = proband\n",
    "            self.group = group\n",
    "            self.parent1 = parent1\n",
    "        \n",
    "    def buildTables(self):\n",
    "        query = \"\"        \n",
    "        query += \"DELETE FROM \" + self.proband + \"VCF where instr(uniLocVCF, 'GL') != 0;\\n\"\n",
    "        query += \"DELETE FROM \" + self.parent1 + \"VCF where instr(uniLocVCF, 'GL') != 0;\\n\"\n",
    "        query += \"CREATE TABLE \" + self.proband + self.group + \"_genotemp1 as select uniLoc, varMD5, geneList, GenotypeVCF proband_geno, \\\n",
    "\\nfunctionGVS, functionDBSNP, aminoAcids, proteinPosition, distanceToSplice, polyPhen, granthamScore, scorePhastCons, scoreCADD, \\\n",
    "\\nF_rarest_allele, MAFinESP, FILTERVCF, \\\n",
    "\\nGenotype_QualityVCF, Variant_Confidence_Quality_by_DepthVCF, \\\n",
    "\\nDepth_CountedVCF depth_proband, Reference_readsVCF Ref_reads_proband, Alt_readsVCF Alt_read_proband, \\\n",
    "\\nRef_read_percentVCF Ref_read_pct_proband, A_readVCF A_read_proband, G_readVCF G_read_proband, \\\n",
    "\\nT_readVCF T_read_proband, C_readVCF C_read_proband, A_percentVCF A_percent_proband, G_percentVCF G_percent_proband, \\\n",
    "\\nT_percentVCF T_percent_proband, C_percentVCF C_percent_proband from \" + self.proband + self.group + \"; \\n\"  \n",
    "        query += \"ALTER TABLE \" + self.proband + self.group + \"_genotemp1 ADD INDEX (uniLoc), ADD INDEX (geneList), ADD INDEX(varMD5);\\n\"\n",
    "        query += \"CREATE TABLE \" + self.proband + self.group + \"_genotypes as select \" + self.proband + self.group + \"_genotemp1.*, \\\n",
    "\\n\" + self.parent1 + \"VCF.GenotypeVCF p1_geno, \" + self.parent1 + \"VCF.Depth_CountedVCF Depth_p1, \\\n",
    "\\n\" + self.parent1 + \"VCF.Reference_readsVCF Ref_read_p1, \" + self.parent1 + \"VCF.Alt_readsVCF Alt_read_p1, \\\n",
    "\\n\" + self.parent1 + \"VCF.Ref_read_percentVCF Ref_read_pct_p1, \" + self.parent1 + \"VCF.A_readVCF A_read_p1, \\\n",
    "\\n\" + self.parent1 + \"VCF.G_readVCF G_read_p1, \" + self.parent1 + \"VCF.T_readVCF T_read_p1, \" + self.parent1 + \"VCF.C_readVCF C_read_p1,\\\n",
    "\\n\" + self.parent1 + \"VCF.A_percentVCF A_percent_p1, \" + self.parent1 + \"VCF.G_percentVCF G_percent_p1, \" + self.parent1 + \"VCF.T_percentVCF T_percent_p1, \\\n",
    "\\n\" + self.parent1 + \"VCF.C_percentVCF C_percent_p1 from \" + self.proband + self.group + \"_genotemp1 left join \" + self.parent1 + \"VCF on \\\n",
    "\\n\" + self.proband + self.group + \"_genotemp1.varMD5 = \" + self.parent1 + \"VCF.varMD5VCF;\\n\"\n",
    "        query += \"DROP TABLE \" + self.proband + self.group + \"_genotemp1;\\n\"\n",
    "        query += \"ALTER TABLE \" + self.proband + group  + \"_genotypes ADD INDEX (uniLoc), ADD INDEX (geneList), ADD INDEX(varMD5);\\n\"\n",
    "        self.genotable = self.proband + self.group + \"_genotypes\"\n",
    "        return query\n",
    "    \n",
    "    def getVariants(self, stringent = False):\n",
    "        query = \"\"\n",
    "        query += \"SELECT * FROM \" + self.proband + self.group + \"_genotypes where \\\n",
    "\\n((substring_index(proband_geno, '/', 1) = substring_index(proband_geno, '/', -1)) and \\\n",
    "\\n(substring_index(p1_geno, '/', 1) != substring_index(p1_geno, '/', -1))) #loss of heterozygosity \\\n",
    "\\nor ((substring_index(proband_geno, '/', 1) != substring_index(proband_geno, '/', -1)) and \\\n",
    "\\n(substring_index(p1_geno, '/', 1) = substring_index(p1_geno, '/', -1))) #gain of heterozygosity \\\n",
    "\\nor (substring_index(proband_geno, '/', 1) not in \\\n",
    "\\n(substring_index(p1_geno, '/', 1), substring_index(p1_geno, '/', -1))) #one allele not found in the parent line\\\n",
    "\\nor (substring_index(proband_geno, '/', -1) not in \\\n",
    "\\n(substring_index(p1_geno, '/', 1), substring_index(p1_geno, '/', -1))) #the other allele not found in the parent line\"\n",
    "        if not stringent:\n",
    "            query += \";\\n\"\n",
    "        if stringent:\n",
    "            query += \"\\nand proband_geno != './.' and p1_geno != './.'; #requires that genotypes were called in both parent and proband;\\n;\"\n",
    "        return query\n",
    "    \n",
    "    def countVariants(self, stringent = False, unique = False):\n",
    "        query = \"\"\n",
    "        if unique:\n",
    "            query += \"SELECT count(distinct varMD5) FROM \"\n",
    "        if not unique:\n",
    "            query += \"SELECT count(*) FROM \"\n",
    "        query += self.proband + self.group + \"_genotypes where \\\n",
    "\\n((substring_index(proband_geno, '/', 1) = substring_index(proband_geno, '/', -1)) and \\\n",
    "\\n(substring_index(p1_geno, '/', 1) != substring_index(p1_geno, '/', -1))) #loss of heterozygosity \\\n",
    "\\nor ((substring_index(proband_geno, '/', 1) != substring_index(proband_geno, '/', -1)) and \\\n",
    "\\n(substring_index(p1_geno, '/', 1) = substring_index(p1_geno, '/', -1))) #gain of heterozygosity \\\n",
    "\\nor (substring_index(proband_geno, '/', 1) not in \\\n",
    "\\n(substring_index(p1_geno, '/', 1), substring_index(p1_geno, '/', -1))) #one allele not found in the parent line\\\n",
    "\\nor (substring_index(proband_geno, '/', -1) not in \\\n",
    "\\n(substring_index(p1_geno, '/', 1), substring_index(p1_geno, '/', -1))) #the other allele not found in the parent line\"\n",
    "        if not stringent:\n",
    "            query += \";\\n\"\n",
    "        if stringent:\n",
    "            query += \"\\nand proband_geno != './.' and p1_geno != './.'; #requires that genotypes were called in both parent and proband;\\n;\"\n",
    "        return query\n",
    "    \n",
    "    \n",
    "class CleanUp(object):\n",
    "    \n",
    "    def rowstring(data, delimiter = \"\\t\", prepend = \"\", append = \"\"):\n",
    "        rowcollector = \"\"\n",
    "        for row in range(0,len(data)):\n",
    "            if delimiter == \"\\t\":\n",
    "                if prepend:\n",
    "                    columncollector = prepend + delimiter\n",
    "                else:\n",
    "                    columncollector = \"\"\n",
    "            else:\n",
    "                if prepend:\n",
    "                    columncollector = '\"' + prepend + '\"' + delimiter + '\"'\n",
    "                else:\n",
    "                    columncollector = '\"'\n",
    "            for column in range(0,len(data[row])):\n",
    "                columncollector += str(data[row][column])\n",
    "                if not (len(data) == 1 and len(data[row]) == 1):\n",
    "                    if column == len(data[row]) -1:\n",
    "                        if delimiter == \"\\t\":\n",
    "                            if append:\n",
    "                                columncollector += delimiter + append + delimiter + \"\\n\"\n",
    "                            else:\n",
    "                                columncollector += \"\\n\"\n",
    "                        else:\n",
    "                            if append:\n",
    "                                columncollector += '\"' + delimiter + '\"' + append + '\"' + \"\\n\"\n",
    "                            else:\n",
    "                                columncollector += '\"' + \"\\n\"\n",
    "                    else:\n",
    "                        if delimiter == \"\\t\":\n",
    "                            columncollector += delimiter\n",
    "                        else:\n",
    "                            columncollector += '\"' + delimiter + '\"'\n",
    "            rowcollector += columncollector\n",
    "        return rowcollector\n",
    "    \n",
    "    def columnstring(data, delimiter = \"\\t\"):\n",
    "        if delimiter == \"\\t\":\n",
    "            rowcollector = \"\"\n",
    "        else:\n",
    "            rowcollector = '\"'\n",
    "        for row in range(0,len(data)):\n",
    "            rowcollector += \"\".join(data[row])\n",
    "            if row == len(data) -1:\n",
    "                if delimiter == \"\\t\":\n",
    "                    rowcollector += \"\\n\"\n",
    "                else:\n",
    "                    rowcollector += '\"' + \"\\n\"\n",
    "            else:\n",
    "                if delimiter == \"\\t\":\n",
    "                    rowcollector += delimiter\n",
    "                else:\n",
    "                    rowcollector += '\"' + delimiter + '\"'\n",
    "        return rowcollector\n",
    "    \n",
    "    def returnToArray(data, singleColumn = False):\n",
    "        rowcollector = []\n",
    "        for row in data:\n",
    "            columncollector = []\n",
    "            for column in row:\n",
    "                columncollector.append(column)\n",
    "            rowcollector.append(columncollector)\n",
    "        if singleColumn:\n",
    "            rowcollector = [item[0] for item in rowcollector]\n",
    "        return rowcollector\n",
    "        \n",
    "        \n",
    "class Sample(object):\n",
    "    \n",
    "    def __init__(self, samples):\n",
    "        try:\n",
    "            self.samples = int(samples)\n",
    "        except:\n",
    "            raise ValueError(\"Number of samples to collect must be an integer (or string of an integer, if you really must)\")\n",
    "        self.collected = 0\n",
    "        self.collection = []\n",
    "        \n",
    "    def collect(self, data):\n",
    "        if self.collected < self.samples:\n",
    "            self.collection.append(data)\n",
    "            self.collected += 1\n",
    "            \n",
    "    def display(self):\n",
    "        for item in self.collection:\n",
    "            print(item)\n",
    "            \n",
    "            \n",
    "class JoinWithVCFTable(object):\n",
    "    \n",
    "    def __init__(self, table, suffix = \"_all\"):\n",
    "        self.table = table\n",
    "        self.suffix = suffix\n",
    "        \n",
    "    def buildTables(self):\n",
    "        query = \"\"\n",
    "        query += \"CREATE TABLE \" + self.table + self.suffix + \" as \\\n",
    "\\nSELECT * from \" + self.table + \" left join \" + self.table + \"VCF on varMD5 = varMD5VCF;\"\n",
    "        self.joinedTable = self.table + self.suffix\n",
    "        return query\n",
    "    \n",
    "def getColumns(schema, table):\n",
    "    query = \"SELECT `COLUMN_NAME` FROM `INFORMATION_SCHEMA`.`COLUMNS` WHERE `TABLE_SCHEMA`='\" + schema + \"' AND `TABLE_NAME`='\" + table + \"';\"\n",
    "    return query\n",
    "    \n",
    "def queryBuilderHelp():\n",
    "    print(\"RareCodingVariants(tablename, suffix) Finds variants annotated as less than 1% allele frequency in all tested populations that are annotated as variant types with the potential to affect protein sequence. Suffix for new table defaults to _rare_coding if not set\\n\\tbuildTables()\\n\\tgetVariants()\\n\\tcountVariants()\")\n",
    "    print(\"KnownGenes(tablename, knownGeneList) Finds variants from the given table in the list of known genes.  knownGeneList should be a list or tupple.\\n\\tlistFromFile(fileObject) (builds a list of genes from a text file, ignores lines starting with a # symbol)\\n\\thashedListFromFile(fileObject) (builds multiple lists of files under one dictionary using lines starting with a # symbol as the key)\\n\\tgetVariants()\")\n",
    "    print(\"Homozygous(tablename, readCutoff, suffix) Creates a table of homozygous variants from the tablename entered.\\nRead cutoff allows for including variants not called as homozygous by the variant caller.\\nNew table suffix defaults to _homozygosity.\\n\\tbuildTables()\\n\\tgetVariants()\\n\\tcountVariants(unique) If the same variant is listed multiple times due to listing each transcript, setting this to True will only count it once (default value is False)\")\n",
    "    print(\"CompoundHet(tablename, suffix) Creates a table of genes with multiple variants.  Default suffix is _compound_het.  VARIANTS MAY OR MAY NOT BE IN PHASE\\n\\tbuildTables()\\n\\tgetVariants()\\n\\tcountVariants(unique)\\n\\tcountGenes() Returns a count of the genes with multiple variants\")\n",
    "    print(\"DeNovoChanges(proband, parent1, parent2, group) Finds variants that have a variant genotype in the proband not found in one of the parents.  Group defaults to an empty string, but can be used to add a suffix to the proband's tablename.\\n\\tbuildTables()\\n\\tgetVariants(stringent) Stringent is a boolean value (True or False) with a default value of False.  If true, will leave out any loci that were not called in one or both parents.\\n\\tcountVariants(stringent, unique)\")\n",
    "    print(\"SomaticChanges(proband, parent1, group) Similar to above, but looks between proband and one parent for any genotypes in the proband not found in the parent, gains of heterozygosity, or losses of heterozygosity.\\n\\tbuildTables()\\n\\tgetVariants(stringent)\\n\\tcountVariants(stringent, unique)\")\n",
    "    print(\"CleanUp() A holder for functions that turn the SQL output into clean strings or lists\\n\\trowstring(data, delimiter) Returns a delimited string (default is tab) of the submitted data.\\n\\tcolumnstring(data, delimiter) Turns a 2-dimensional output into a 1-line dimensional string (useful for column headers)\\n\\trowarray(data) Returns a 2-dimensional array of data\\n\\tcolumnarray(data)\")\n",
    "    print(\"Sample(numberOfSamples) Sets up an object to store the number of samples given.\\n\\tcollect(data) Stores the data as a sample.\\n\\tdisplay() Prints the collected samples.\")\n",
    "    print(\"JoinWithVCFTable(tablename, suffix) Joins the annotation (SeattleSeq) data with the matching VCF data for that variant in the tablename submitted.  Suffix default is _all.\\n\\tbuildTables()\")\n",
    "    print(\"getColumns(schema, tablename) Gets a list of column names from the schema and tablename.  Data returned as a column of tupples each containing one column name. (Use columnstring or column array to clean).\")   \n",
    "\n",
    "\n",
    "class Recurrents(object):\n",
    "    \n",
    "    def __init__(self, caseDB, caseTableList, controlDB=False, controlTableList=[]):\n",
    "        self.cases = caseTableList\n",
    "        self.controls = controlTableList\n",
    "        self.caseDB = caseDB\n",
    "        self.controlDB = controlDB\n",
    "        self.caseCounts = self.getCaseCounts(self.caseDB, self.cases)\n",
    "        if self.controlDB and self.controls:\n",
    "            self.controlCounts = self.getControlCounts(self.controlDB, self.controls)\n",
    "        else:\n",
    "            self.controlCounts = False\n",
    "            \n",
    "    def getCaseCounts(self, dbConnection, tables):\n",
    "        md5collector = []\n",
    "        for table in tables:\n",
    "            query = \"Select varMD5 from \" + table\n",
    "            dbConnection.execute(query)\n",
    "            md5list = dbConnection.fetchall()\n",
    "            md5list = CleanUp.returnToArray(md5list, \"SingleColumn\")\n",
    "            md5collector += md5list\n",
    "        counts = MapReduce(md5collector)\n",
    "        self.caseRecurrenceList = counts.reduced\n",
    "        self.caseRecurrenceHash = counts.hashTable\n",
    "        self.caseVariantList = counts.map\n",
    "        \n",
    "    def getControlCounts(self, dbConnection, tables):\n",
    "        md5collector = []\n",
    "        for table in tables:\n",
    "            query = \"Select varMD5 from \" + table\n",
    "            dbConnection.execute(query)\n",
    "            md5list = dbConnection.fetchall()\n",
    "            md5list = CleanUp.returnToArray(md5list, \"SingleColumn\")\n",
    "            md5collector += md5list\n",
    "        counts = MapReduce(md5collector)\n",
    "        self.controlRecurrenceList = counts.reduced\n",
    "        self.controlRecurrenceHash = counts.hashTable\n",
    "        self.controlVariantList = counts.map\n",
    "        \n",
    "    def hashByCount(self, control = False):\n",
    "        output = {}\n",
    "        if control:\n",
    "            hashTable = self.controlRecurrenceHash\n",
    "            maxRecurrences = len(self.controls)\n",
    "        else:\n",
    "            hashTable = self.caseRecurrenceHash\n",
    "            maxRecurrences = len(self.cases)\n",
    "        for count in range(1,maxRecurrences + 1):\n",
    "            output[count] = []\n",
    "        for key in list(hashTable.keys()):\n",
    "            output[hashTable[key]].append(key)\n",
    "        return output\n",
    "    \n",
    "class multiTableFind(object):\n",
    "    def __init__(self, dbconnection, schema, columnName, matchCriteria, tableList, returnColumns = \"*\"):\n",
    "        self.columnName = columnName\n",
    "        self.matchCriteria = matchCriteria\n",
    "        self.matchCriteriaString = \"'\" + \"', '\".join(matchCriteria) + \"'\"\n",
    "        self.tableList = tableList\n",
    "        self.returnColumns = returnColumns\n",
    "        self.dbconnection = dbconnection\n",
    "        self.schema = schema\n",
    "        self.returnColumnsString = \"*\"\n",
    "        if self.returnColumns != \"*\":\n",
    "            self.returnColumnsString = \", \".join(returnColumns)\n",
    "            self.headerList = returnColumns\n",
    "        if not self.validateColumns():\n",
    "            if self.returnColumns != \"*\":\n",
    "                raise RuntimeError(\"The following requested columns are missing (shown as table.column):\\n\" + \"\\n\".join(self.missingColumns))\n",
    "            else:\n",
    "                tableDebug = \"\"\n",
    "                for table in self.tableList:\n",
    "                    tableDebug += \"\\t\".join([table,self.tableDebugHash[table][0],self.tableDebugHash[table][1]]) + \"\\n\"\n",
    "                raise RuntimeError(\"All tables must have the same headers if all columns are requested in the return.\\\n",
    "                \\nDebugging information as follows:\\n\" + tableDebug)\n",
    "        else:\n",
    "            self.run()\n",
    "                \n",
    "    def validateColumns(self):\n",
    "        import hashlib\n",
    "        passedCheck = True\n",
    "        if self.returnColumns == \"*\":\n",
    "            self.tableDebugHash = {}\n",
    "            firstHeader = []\n",
    "            for table in self.tableList:\n",
    "                self.dbconnection.execute(getColumns(self.schema, table))\n",
    "                result = self.dbconnection.fetchall()\n",
    "                result = CleanUp.returnToArray(result, singleColumn = True)\n",
    "                result[88] = \"original_sample_info\"  #if annotation columns change, this will have to be changed with it to a new index\n",
    "                headerString = \"\".join(result)\n",
    "                self.tableDebugHash[table] = [str(len(result)), hashlib.md5(headerString.encode('utf-8')).hexdigest()]\n",
    "                #print(result)\n",
    "                if not firstHeader:\n",
    "                    firstHeader = result\n",
    "                    self.headerList = result\n",
    "                else:\n",
    "                    for i in range(0,len(firstHeader)):\n",
    "                        if result[i] != firstHeader[i]:\n",
    "                            print(str(i) + \"\\n\" + result[i] + \"\\n\" + firstHeader[i])\n",
    "                            passedCheck = False\n",
    "            #        if result != firstHeader:\n",
    "            #            passedCheck = False\n",
    "        else:\n",
    "            self.missingColumns = []\n",
    "            for table in self.tableList:\n",
    "                self.dbconnection.execute(getColumns(self.schema, table))\n",
    "                result = self.dbconnection.fetchall()\n",
    "                result = CleanUp.returnToArray(result, singleColumn = True)\n",
    "                for column in self.returnColumns:\n",
    "                    if not column in result:\n",
    "                        self.missingColumns.append(\".\".join([table,column]))\n",
    "                        passedCheck = False\n",
    "        return passedCheck\n",
    "    \n",
    "    \n",
    "    def run(self):\n",
    "        self.result = {}\n",
    "        for table in self.tableList:\n",
    "            query = \"SELECT \" + self.returnColumnsString + \" from \" + table + \" WHERE \" + self.columnName + \" in (\" + self.matchCriteriaString + \");\\n\"\n",
    "            self.dbconnection.execute(query)\n",
    "            returned = self.dbconnection.fetchall()\n",
    "            returned = CleanUp.returnToArray(returned)\n",
    "            self.result[table] = returned\n",
    "        return True\n",
    "    \n",
    "    def makePandas(self):\n",
    "        import pandas\n",
    "        thisWillProbablyFail = (ValueError, TypeError)\n",
    "        pandaHeaders = ['source'] + self.headerList\n",
    "        pandaPrep = {}\n",
    "        for header in pandaHeaders:\n",
    "            pandaPrep[header] = []\n",
    "        for key in (self.result.keys()):\n",
    "            for line in self.result[key]:\n",
    "                position = 1 #index to 1 because we add the source value by name\n",
    "                pandaPrep['source'].append(key)\n",
    "                for element in line:\n",
    "                    try:\n",
    "                        element = int(element)\n",
    "                    except thisWillProbablyFail:\n",
    "                        try:\n",
    "                            element = float(element)\n",
    "                        except thisWillProbablyFail:\n",
    "                            pass\n",
    "                    pandaPrep[pandaHeaders[position]].append(element)\n",
    "                    position += 1\n",
    "        df =  pandas.DataFrame(pandaPrep)\n",
    "        return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
